{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f2b41-652f-4382-bcb9-e73a67b81d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is anomaly detection and what is its purpose?\n",
    "\"\"\"\n",
    "Anomaly detection is a technique used to identify patterns or instances that deviate significantly from the normal behavior or expected patterns \n",
    "in a dataset. Anomalies, also known as outliers, are data points or patterns that differ from the majority of the data and may indicate unusual or \n",
    "potentially interesting observations.\n",
    "\n",
    "The purpose of anomaly detection is to detect and identify these unusual patterns or instances that do not conform to the expected behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3f050-77fc-4489-baa3-a1ba8f653d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the key challenges in anomaly detection?\n",
    "\"\"\"\n",
    "The key challenges in anomaly detection include:\n",
    "\n",
    "1. Lack of labeled data: Anomalies are often rare and unexpected, making it difficult to obtain a sufficient amount of labeled data for training \n",
    "        anomaly detection models.\n",
    "\n",
    "2. Imbalanced datasets: Anomalies typically represent a small portion of the overall dataset, leading to imbalanced class distributions. This can \n",
    "        result in biased models that struggle to accurately detect anomalies.\n",
    "\n",
    "3. Dynamic and evolving anomalies: Anomalies can change over time, requiring anomaly detection models to adapt and be capable of detecting new and \n",
    "        emerging anomalies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a8978b-354d-435e-86d0-7ac0d1468c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\"\"\"\n",
    "Unsupervised Anomaly Detection:\n",
    "1. Approach: Unsupervised anomaly detection does not require labeled data or prior knowledge of anomalies. It focuses on identifying patterns or \n",
    "    instances that deviate significantly from the normal behavior observed in the dataset.\n",
    "2. Training: Unsupervised methods learn from the characteristics of the majority of the data to establish a notion of \"normal\" behavior. They aim to \n",
    "    find anomalies that do not conform to the learned normal patterns.\n",
    "3. Anomaly Detection: Unsupervised methods detect anomalies by comparing data points to the learned normal patterns or by identifying statistical \n",
    "    deviations, clustering anomalies away from the majority of the data, or using density-based techniques.\n",
    "4. Applicability: Unsupervised anomaly detection is useful when labeled anomalies are scarce or unavailable, and the goal is to discover unknown or \n",
    "    novel anomalies in the data.\n",
    "    \n",
    "Supervised Anomaly Detection:\n",
    "1. Approach: Supervised anomaly detection requires labeled data where anomalies are explicitly identified. It involves training a model to classify \n",
    "    instances as normal or anomalous based on the provided labels.\n",
    "2. Training: Supervised methods learn from labeled data, which consists of both normal and anomalous instances, and build a model that can generalize\n",
    "    from these labeled examples.\n",
    "3. Anomaly Detection: Once trained, supervised models can predict and classify new instances as normal or anomalous based on the patterns learned \n",
    "    during training. They rely on the labeled anomalies to guide their decision-making process.\n",
    "4. Applicability: Supervised anomaly detection is suitable when labeled examples of anomalies are available, and the focus is on classifying new \n",
    "    instances as either normal or anomalous based on the learned patterns.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00e66c-89bc-4091-9ad9-84d5c55c89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What are the main categories of anomaly detection algorithms?\n",
    "\"\"\"\n",
    "Anomaly detection algorithms can be broadly categorized into the following main categories:\n",
    "\n",
    "Statistical Methods:\n",
    "1. Gaussian Distribution: These methods assume that the data follows a Gaussian (normal) distribution, and anomalies are identified as instances that\n",
    "    significantly deviate from the expected distribution.\n",
    "2. Extreme Value Analysis: These methods focus on modeling the tail behavior of the data distribution and identify anomalies as extreme values that \n",
    "    fall outside a predefined threshold.\n",
    "    \n",
    "Machine Learning Methods:\n",
    "1. Clustering-Based: These methods group similar instances together and identify anomalies as data points that do not belong to any cluster or are \n",
    "    distant from any cluster center.\n",
    "2. Density-Based: These methods estimate the density of the data and identify anomalies as instances that lie in regions of low density.\n",
    "3. Isolation Forest: This method constructs random decision trees to isolate anomalies by identifying instances that require fewer partitions to be \n",
    "    separated from the majority of the data.\n",
    "4. k-Nearest Neighbors (k-NN): These methods measure the distance or similarity between instances and identify anomalies as data points that have \n",
    "    few or no nearby neighbors.\n",
    "5. Local Outlier Factor (LOF): LOF calculates the density of an instance compared to its neighbors and identifies anomalies as instances with a \n",
    "    significantly lower density.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "442c4d99-efc9-4663-bcc8-248e6488c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\"\"\"\n",
    "Distance-based anomaly detection methods rely on certain assumptions to identify anomalies based on the distances or dissimilarities between data \n",
    "points. The main assumptions made by distance-based anomaly detection methods include:\n",
    "\n",
    "1. Normality Assumption: These methods assume that the majority of the data points in a dataset represent normal or non-anomalous instances. Anomalies\n",
    "    are considered as deviations from this normal behavior.\n",
    "\n",
    "2. Distance Metric Assumption: Distance-based methods assume the availability of a meaningful distance metric or dissimilarity measure that quantifies\n",
    "    the similarity or dissimilarity between data points. Common distance metrics include Euclidean distance, Mahalanobis distance, cosine similarity, \n",
    "    or other domain-specific similarity measures.\n",
    "\n",
    "3. Nearest Neighbor Assumption: These methods often assume that anomalies are located far away from their nearest neighbors or have fewer neighbors\n",
    "    compared to normal instances. Anomalies are expected to have dissimilarities or distances that exceed a certain threshold.\n",
    "\n",
    "4. Density-Based Assumption: Some distance-based methods assume that anomalies lie in regions of low data density or have dissimilarities that deviate\n",
    "    significantly from the average dissimilarity of the data. Anomalies are identified as instances that are sparsely surrounded by other data points.\n",
    "\n",
    "5. Independence Assumption: Distance-based methods often assume that the attributes or dimensions of the data are independent and do not have strong \n",
    "    correlations. This assumption allows the distances between instances to be appropriately computed and interpreted.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a751c7-337e-498d-bc78-d93e9830ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\"\"\"\n",
    "The LOF (Local Outlier Factor) algorithm computes anomaly scores by comparing the local density of a data point with the densities of its neighbors. \n",
    "It measures the degree to which a point is an outlier by considering the ratio of the average local density of its k-nearest neighbors to its own \n",
    "local density, where a significantly lower ratio indicates a higher anomaly score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc059c-e48b-4bb7-a5d2-37f1c65d818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\"\"\"\n",
    "The Isolation Forest algorithm has two key parameters:\n",
    "\n",
    "1. n_estimators: This parameter specifies the number of isolation trees to be created in the forest.\n",
    "\n",
    "2. contamination: This parameter defines the expected proportion of anomalies in the dataset. \n",
    "\n",
    "3. max_depth: It limits the maximum depth or height of each isolation tree. \n",
    "\n",
    "4. max_samples: It specifies the number of samples to be used when creating each isolation tree.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630a765c-0b4e-437c-8f1f-cc13c3200db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "\"\"\"\n",
    "Since there are only 2 neighbors within the radius of 0.5, it is not possible to calculate the anomaly score based on KNN with K=10. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77149000-0fb4-4fc6-adb5-a18c655346c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an \n",
    "#    average path length of 5.0 compared to the average path length of the trees?\n",
    "\"\"\"\n",
    "E(h(x)) = 5\n",
    "c(m) = 3000/100 = 30\n",
    "\n",
    "Anomaly score S(x,m) = 2 ^ -E(h(x))/c(m)\n",
    "                     = 2^ -5/30\n",
    "                     = 0.31\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
